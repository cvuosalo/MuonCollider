nohup: ignoring input

Processing Pairing_w_bkg_JES.C("delphes_dhiggs_sig_10k.root","delphes_dhiggs_bkg2v4b_10k.root","delphes_dhiggs_bkgvvbbh_10k.root","delphes_dhiggs_bkgvvbbz_10k.root","delphes_dhiggs_sig+bkg_pairmass.root","/nfs_scratch/hjia38/ttbar_w_hadron.root","ttbar_w_hadron_Cali.root")...

Calling Calibration algorithm...

Initiating Calibration...

Calibration's result:
Jet Energy Calibration gives following Jet Energy Response:
1, 0.98, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.97, 0.99, 
1.02, 0.96, 0.94, 0.95, 1, 0.97, 0.96, 0.94, 0.94, 0.99, 
1.01, 0.97, 0.95, 0.97, 0.96, 1.01, 0.98, 0.95, 0.93, 0.97, 
0.99, 0.95, 0.96, 0.99, 0.97, 0.98, 0.95, 0.97, 0.94, 0.96, 
0.99, 0.95, 1.01, 0.97, 0.96, 0.97, 0.98, 0.97, 0.94, 0.96, 
0.97, 0.94, 0.96, 0.98, 1, 0.99, 0.98, 0.96, 0.96, 0.95, 
0.95, 0.96, 0.98, 0.99, 0.99, 1.03, 0.99, 0.98, 0.97, 0.95, 
0.95, 0.97, 0.99, 1, 0.99, 1, 0.99, 0.97, 0.99, 0.95, 
0.93, 0.98, 0.99, 0.99, 1, 1, 1, 1, 0.99, 0.94, 
0.89, 0.97, 0.98, 0.98, 0.99, 0.98, 0.98, 0.98, 0.98, 0.9, 

Number of Jets included in calculation
0, 1084, 1776, 1492, 1429, 1302, 1438, 1653, 1747, 191, 
1, 326, 100, 80, 80, 75, 80, 89, 206, 178, 
19, 356, 114, 90, 82, 66, 82, 103, 198, 230, 
47, 352, 129, 92, 88, 113, 99, 101, 179, 297, 
112, 346, 148, 111, 105, 101, 112, 132, 197, 306, 
160, 422, 167, 173, 146, 133, 153, 170, 236, 446, 
340, 578, 270, 215, 221, 241, 227, 223, 388, 655, 
499, 784, 506, 376, 336, 370, 370, 397, 600, 854, 
705, 1389, 1008, 823, 757, 713, 748, 887, 1139, 1490, 
720, 1497, 1339, 1244, 1145, 1076, 1191, 1307, 1516, 1476, 

Calibration all done! Quit...

///////////////////////////////////////////////////
Initiating pairing algorithm...
Done

///////////////////////////////////////////////////
Initiating pairing algorithm...
Done

///////////////////////////////////////////////////
Initiating pairing algorithm...
Done

///////////////////////////////////////////////////
Initiating pairing algorithm...
Done
                         : Parsing option string: 
                         : ... "V:!Silent:Color:Transformations=I:DrawProgressBar:AnalysisType=Classification"
                         : The following options are set:
                         : - By User:
                         :     V: "True" [Verbose flag]
                         :     Color: "True" [Flag for coloured screen output (default: True, if in batch mode: False)]
                         :     Transformations: "I" [List of transformations to test; formatting example: "Transformations=I;D;P;U;G,D", for identity, decorrelation, PCA, Uniform and Gaussianisation followed by decorrelation transformations]
                         :     Silent: "False" [Batch mode: boolean silent flag inhibiting any output from TMVA after the creation of the factory class object (default: False)]
                         :     DrawProgressBar: "True" [Draw progress bar to display training, testing and evaluation schedule (default: True)]
                         :     AnalysisType: "Classification" [Set the analysis type (Classification, Regression, Multiclass, Auto) (default: Auto)]
                         : - Default:
                         :     VerboseLevel: "Info" [VerboseLevel (Debug/Verbose/Info)]
                         :     Correlations: "False" [boolean to show correlation in output]
                         :     ROC: "True" [boolean to show ROC in output]
                         :     ModelPersistence: "True" [Option to save the trained model in xml file or using serialization]
create data set info dataset
DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree tree_BDT_sig of type Signal with 3916 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree tree_BDT_bkg3 of type Background with 2538 events
Factory                  : Booking method: [1mMLP[0m
                         : 
MLP                      : [dataset] : Create Transformation "N" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'BDTNjets' <---> Output : variable 'BDTNjets'
                         : Input : variable 'BDTjet1eta1' <---> Output : variable 'BDTjet1eta1'
                         : Input : variable 'BDTjet1eta2' <---> Output : variable 'BDTjet1eta2'
                         : Input : variable 'BDTjet2eta1' <---> Output : variable 'BDTjet2eta1'
                         : Input : variable 'BDTjet2eta2' <---> Output : variable 'BDTjet2eta2'
                         : Input : variable 'BDThiggs1invm' <---> Output : variable 'BDThiggs1invm'
                         : Input : variable 'BDThiggs2invm' <---> Output : variable 'BDThiggs2invm'
                         : Input : variable 'BDTdihiggspt' <---> Output : variable 'BDTdihiggspt'
MLP                      : Building Network. 
                         : Initializing weights
Factory                  : [1mTrain all methods[0m
                         : Building event vectors for type 2 Signal
                         : Dataset[dataset] :  create input formulas for tree tree_BDT_sig
                         : Building event vectors for type 2 Background
                         : Dataset[dataset] :  create input formulas for tree tree_BDT_bkg3
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Dataset[dataset] : Weight renormalisation mode: "EqualNumEvents": renormalises all event classes ...
                         : Dataset[dataset] :  such that the effective (weighted) number of events in each class is the same 
                         : Dataset[dataset] :  (and equals the number of events (entries) given for class=0 )
                         : Dataset[dataset] : ... i.e. such that Sum[i=1..N_j]{w_i} = N_classA, j=classA, classB, ...
                         : Dataset[dataset] : ... (note that N_j is the sum of TRAINING events
                         : Dataset[dataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor!)
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 1958
                         : Signal     -- testing events             : 1958
                         : Signal     -- training and testing events: 3916
                         : Background -- training events            : 1269
                         : Background -- testing events             : 1269
                         : Background -- training and testing events: 2538
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : ----------------------------------------------------------------------------------------------------------------
                         :                BDTNjets BDTjet1eta1 BDTjet1eta2 BDTjet2eta1 BDTjet2eta2 BDThiggs1invm BDThiggs2invm BDTdihiggspt
                         :      BDTNjets:   +1.000      -0.010      +0.025      +0.030      +0.001        +0.075        +0.032       -0.094
                         :   BDTjet1eta1:   -0.010      +1.000      +0.157      +0.208      -0.119        -0.029        -0.022       -0.004
                         :   BDTjet1eta2:   +0.025      +0.157      +1.000      -0.077      +0.269        -0.013        -0.033       -0.004
                         :   BDTjet2eta1:   +0.030      +0.208      -0.077      +1.000      +0.323        -0.043        -0.006       -0.008
                         :   BDTjet2eta2:   +0.001      -0.119      +0.269      +0.323      +1.000        -0.032        -0.017       -0.000
                         : BDThiggs1invm:   +0.075      -0.029      -0.013      -0.043      -0.032        +1.000        +0.552       -0.120
                         : BDThiggs2invm:   +0.032      -0.022      -0.033      -0.006      -0.017        +0.552        +1.000       -0.020
                         :  BDTdihiggspt:   -0.094      -0.004      -0.004      -0.008      -0.000        -0.120        -0.020       +1.000
                         : ----------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : ----------------------------------------------------------------------------------------------------------------
                         :                BDTNjets BDTjet1eta1 BDTjet1eta2 BDTjet2eta1 BDTjet2eta2 BDThiggs1invm BDThiggs2invm BDTdihiggspt
                         :      BDTNjets:   +1.000      +0.017      +0.005      -0.025      +0.013        +0.023        +0.011       +0.007
                         :   BDTjet1eta1:   +0.017      +1.000      +0.308      +0.408      +0.070        -0.028        -0.020       -0.010
                         :   BDTjet1eta2:   +0.005      +0.308      +1.000      +0.097      +0.413        -0.070        -0.039       -0.005
                         :   BDTjet2eta1:   -0.025      +0.408      +0.097      +1.000      +0.412        -0.018        +0.024       +0.017
                         :   BDTjet2eta2:   +0.013      +0.070      +0.413      +0.412      +1.000        +0.039        +0.027       +0.051
                         : BDThiggs1invm:   +0.023      -0.028      -0.070      -0.018      +0.039        +1.000        +0.583       +0.045
                         : BDThiggs2invm:   +0.011      -0.020      -0.039      +0.024      +0.027        +0.583        +1.000       +0.001
                         :  BDTdihiggspt:   +0.007      -0.010      -0.005      +0.017      +0.051        +0.045        +0.001       +1.000
                         : ----------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'BDTNjets' <---> Output : variable 'BDTNjets'
                         : Input : variable 'BDTjet1eta1' <---> Output : variable 'BDTjet1eta1'
                         : Input : variable 'BDTjet1eta2' <---> Output : variable 'BDTjet1eta2'
                         : Input : variable 'BDTjet2eta1' <---> Output : variable 'BDTjet2eta1'
                         : Input : variable 'BDTjet2eta2' <---> Output : variable 'BDTjet2eta2'
                         : Input : variable 'BDThiggs1invm' <---> Output : variable 'BDThiggs1invm'
                         : Input : variable 'BDThiggs2invm' <---> Output : variable 'BDThiggs2invm'
                         : Input : variable 'BDTdihiggspt' <---> Output : variable 'BDTdihiggspt'
TFHandler_Factory        :      Variable             Mean             RMS     [        Min             Max ]
                         : ------------------------------------------------------------------------------------
                         :      BDTNjets:         4.1448        0.39548   [         4.0000         7.0000 ]
                         :   BDTjet1eta1:       0.054067         1.2421   [        -2.4167         2.4662 ]
                         :   BDTjet1eta2:       0.037021         1.2813   [        -2.4600         2.4791 ]
                         :   BDTjet2eta1:      0.0094838         1.2347   [        -2.4381         2.4678 ]
                         :   BDTjet2eta2:       0.024120         1.2938   [        -2.4763         2.4877 ]
                         : BDThiggs1invm:         119.43         24.693   [         0.0000         219.76 ]
                         : BDThiggs2invm:         98.409         26.043   [         0.0000         192.16 ]
                         :  BDTdihiggspt:         146.29         125.79   [         1.3824         1753.8 ]
                         : ------------------------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
IdTransformation         : Ranking result (top variable is best ranked)
                         : --------------------------------------
                         : Rank : Variable      : Separation
                         : --------------------------------------
                         :    1 : BDThiggs2invm : 4.922e-02
                         :    2 : BDTdihiggspt  : 4.741e-02
                         :    3 : BDThiggs1invm : 4.214e-02
                         :    4 : BDTNjets      : 3.519e-02
                         :    5 : BDTjet1eta1   : 2.593e-02
                         :    6 : BDTjet2eta2   : 2.384e-02
                         :    7 : BDTjet1eta2   : 1.721e-02
                         :    8 : BDTjet2eta1   : 1.443e-02
                         : --------------------------------------
Factory                  : Train method: MLP for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ MLP ] :[0m
                         : 
                         : [1m--- Short description:[0m
                         : 
                         : The MLP artificial neural network (ANN) is a traditional feed-
                         : forward multilayer perceptron implementation. The MLP has a user-
                         : defined hidden layer architecture, while the number of input (output)
                         : nodes is determined by the input variables (output classes, i.e., 
                         : signal and one background). 
                         : 
                         : [1m--- Performance optimisation:[0m
                         : 
                         : Neural networks are stable and performing for a large variety of 
                         : linear and non-linear classification problems. However, in contrast
                         : to (e.g.) boosted decision trees, the user is advised to reduce the 
                         : number of input variables that have only little discrimination power. 
                         : 
                         : In the tests we have carried out so far, the MLP and ROOT networks
                         : (TMlpANN, interfaced via TMVA) performed equally well, with however
                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural 
                         : net (CFMlpANN) exhibited worse classification performance in these
                         : tests, which is partly due to the slow convergence of its training
                         : (at least 10k training cycles are required to achieve approximately
                         : competitive results).
                         : 
                         : [1mOvertraining: [0monly the TMlpANN performs an explicit separation of the
                         : full training sample into independent training and validation samples.
                         : We have found that in most high-energy physics applications the 
                         : available degrees of freedom (training events) are sufficient to 
                         : constrain the weights of the relatively simple architectures required
                         : to achieve good performance. Hence no overtraining should occur, and 
                         : the use of validation samples would only reduce the available training
                         : information. However, if the performance on the training sample is 
                         : found to be significantly better than the one found with the inde-
                         : pendent test sample, caution is needed. The results for these samples 
                         : are printed to standard output at the end of each training job.
                         : 
                         : [1m--- Performance tuning via configuration options:[0m
                         : 
                         : The hidden layer architecture for all ANNs is defined by the option
                         : "HiddenLayers=N+1,N,...", where here the first hidden layer has N+1
                         : neurons and the second N neurons (and so on), and where N is the number  
                         : of input variables. Excessive numbers of hidden layers should be avoided,
                         : in favour of more neurons in the first hidden layer.
                         : 
                         : The number of cycles should be above 500. As said, if the number of
                         : adjustable weights is small compared to the training sample size,
                         : using a large number of training samples should not lead to overtraining.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
TFHandler_MLP            :      Variable             Mean             RMS     [        Min             Max ]
                         : ------------------------------------------------------------------------------------
                         :      BDTNjets:       -0.90348        0.26365   [        -1.0000         1.0000 ]
                         :   BDTjet1eta1:       0.012015        0.50878   [        -1.0000         1.0000 ]
                         :   BDTjet1eta2:       0.011131        0.51886   [        -1.0000         1.0000 ]
                         :   BDTjet2eta1:     -0.0022017        0.50334   [        -1.0000         1.0000 ]
                         :   BDTjet2eta2:      0.0074099        0.52126   [        -1.0000         1.0000 ]
                         : BDThiggs1invm:       0.086939        0.22473   [        -1.0000         1.0000 ]
                         : BDThiggs2invm:       0.024234        0.27106   [        -1.0000         1.0000 ]
                         :  BDTdihiggspt:       -0.83461        0.14356   [        -1.0000         1.0000 ]
                         : ------------------------------------------------------------------------------------
                         : Training Network
                         : 
0%, time left: unknown
6%, time left: 272 sec
12%, time left: 252 sec
18%, time left: 234 sec
25%, time left: 216 sec
31%, time left: 198 sec
37%, time left: 180 sec
43%, time left: 162 sec
50%, time left: 144 sec
56%, time left: 126 sec
62%, time left: 108 sec
68%, time left: 90 sec
75%, time left: 72 sec
81%, time left: 53 sec
87%, time left: 36 sec
93%, time left: 17 sec
                         : Elapsed time for training with 3227 events: 288 sec         
MLP                      : [dataset] : Evaluation of MLP on training sample (3227 events)
0%, time left: unknown
6%, time left: 0 sec
12%, time left: 0 sec
18%, time left: 0 sec
25%, time left: 0 sec
31%, time left: 0 sec
37%, time left: 0 sec
44%, time left: 0 sec
50%, time left: 0 sec
56%, time left: 0 sec
63%, time left: 0 sec
69%, time left: 0 sec
75%, time left: 0 sec
81%, time left: 0 sec
88%, time left: 0 sec
94%, time left: 0 sec
                         : Elapsed time for evaluation of 3227 events: 0.019 sec       
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_MLP.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_MLP.class.C[0m
                         : Write special histos to file: delphes_dhiggs_sig+bkg_BDT.root:/dataset/Method_MLP/MLP
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
MLP                      : Ranking result (top variable is best ranked)
                         : --------------------------------------
                         : Rank : Variable      : Importance
                         : --------------------------------------
                         :    1 : BDTNjets      : 5.851e+01
                         :    2 : BDTdihiggspt  : 5.825e+01
                         :    3 : BDThiggs2invm : 2.525e+01
                         :    4 : BDTjet1eta1   : 2.386e+01
                         :    5 : BDTjet2eta2   : 2.187e+01
                         :    6 : BDTjet1eta2   : 1.998e+01
                         :    7 : BDTjet2eta1   : 1.672e+01
                         :    8 : BDThiggs1invm : 7.130e+00
                         : --------------------------------------
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_MLP.weights.xml[0m
MLP                      : Building Network. 
                         : Initializing weights
Factory                  : [1mTest all methods[0m
Factory                  : Test method: MLP for Classification performance
                         : 
MLP                      : [dataset] : Evaluation of MLP on testing sample (3227 events)
0%, time left: unknown
6%, time left: 0 sec
12%, time left: 0 sec
18%, time left: 0 sec
25%, time left: 0 sec
31%, time left: 0 sec
37%, time left: 0 sec
44%, time left: 0 sec
50%, time left: 0 sec
56%, time left: 0 sec
63%, time left: 0 sec
69%, time left: 0 sec
75%, time left: 0 sec
81%, time left: 0 sec
88%, time left: 0 sec
94%, time left: 0 sec
                         : Elapsed time for evaluation of 3227 events: 0.0188 sec       
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: MLP
                         : 
TFHandler_MLP            :      Variable             Mean             RMS     [        Min             Max ]
                         : ------------------------------------------------------------------------------------
                         :      BDTNjets:       -0.88927        0.27397   [        -1.0000         1.0000 ]
                         :   BDTjet1eta1:    -8.5999e-05        0.50432   [        -1.0070         1.0031 ]
                         :   BDTjet1eta2:     -0.0015338        0.51618   [        -1.0022        0.99911 ]
                         :   BDTjet2eta1:      0.0010491        0.50316   [       -0.99826         1.0049 ]
                         :   BDTjet2eta2:     -0.0057126        0.51467   [       -0.99560        0.99563 ]
                         : BDThiggs1invm:        0.10707        0.21830   [        -1.0000        0.99332 ]
                         : BDThiggs2invm:       0.037135        0.26954   [        -1.0000         1.2362 ]
                         :  BDTdihiggspt:       -0.84141        0.13193   [       -0.99999         1.1963 ]
                         : ------------------------------------------------------------------------------------
MLP                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_MLP            :      Variable             Mean             RMS     [        Min             Max ]
                         : ------------------------------------------------------------------------------------
                         :      BDTNjets:       -0.88927        0.27397   [        -1.0000         1.0000 ]
                         :   BDTjet1eta1:    -8.5999e-05        0.50432   [        -1.0070         1.0031 ]
                         :   BDTjet1eta2:     -0.0015338        0.51618   [        -1.0022        0.99911 ]
                         :   BDTjet2eta1:      0.0010491        0.50316   [       -0.99826         1.0049 ]
                         :   BDTjet2eta2:     -0.0057126        0.51467   [       -0.99560        0.99563 ]
                         : BDThiggs1invm:        0.10707        0.21830   [        -1.0000        0.99332 ]
                         : BDThiggs2invm:       0.037135        0.26954   [        -1.0000         1.2362 ]
                         :  BDTdihiggspt:       -0.84141        0.13193   [       -0.99999         1.1963 ]
                         : ------------------------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       MLP            : 0.705
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              MLP            : 0.088 (0.199)       0.338 (0.428)      0.598 (0.679)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 3227 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 3227 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
Time taken: 834.29s
All done! Exit...
